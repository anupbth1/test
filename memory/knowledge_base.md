# AI_RESEARCHER Knowledge Base

## Known Effective Techniques
- Mixed quantization improves CPU efficiency
- Q4_K_M is a strong baseline
- KV-cache aggressive quant saves RAM

## Known Limitations
- CPU training is slow
- Extremely low quant harms reasoning
- Over-pruning causes instability

## References
- llama.cpp documentation
- LoRA / QLoRA research

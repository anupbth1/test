# Model Architecture Notes

- Transformer baseline
- Attention layers most sensitive
- MLP layers tolerate lower precision
- Output head critical for quality

Do NOT change architecture blindly.
Test every change.
